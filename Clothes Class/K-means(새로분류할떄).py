import os
import shutil
import numpy as np
import cv2
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from tqdm import tqdm
import gc
import tensorflow as tf
from tensorflow.keras import backend as K
import psutil
import logging
import json
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiCategoryImageClassifier:
    def __init__(self, base_folder, n_clusters=10, batch_size=8, skip_completed=True):
        self.base_folder = base_folder
        self.n_clusters = n_clusters
        self.batch_size = batch_size
        self.skip_completed = skip_completed
        self.model = None
        self.progress_file = os.path.join(base_folder, "classification_progress.json")
        self.completed_categories = self._load_progress()
        self._initialize_model()
        
    def _load_progress(self):
        """ì´ì „ ì‘ì—… ì§„í–‰ìƒí™© ë¡œë“œ"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
                    completed = set(progress_data.get('completed_categories', []))
                    logger.info(f"ì´ì „ ì§„í–‰ìƒí™© ë¡œë“œ: {len(completed)}ê°œ ì¹´í…Œê³ ë¦¬ ì™„ë£Œë¨")
                    return completed
            except Exception as e:
                logger.warning(f"ì§„í–‰ìƒí™© íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return set()
    
    def _save_progress(self, category_name):
        """ì‘ì—… ì§„í–‰ìƒí™© ì €ì¥"""
        self.completed_categories.add(category_name)
        progress_data = {
            'completed_categories': list(self.completed_categories),
            'last_updated': datetime.now().isoformat(),
            'total_completed': len(self.completed_categories)
        }
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ì§„í–‰ìƒí™© ì €ì¥: {category_name} ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ì§„í–‰ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _is_category_completed(self, category_info):
        """ì¹´í…Œê³ ë¦¬ê°€ ì´ë¯¸ ë¶„ë¥˜ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        # 1. ì§„í–‰ìƒí™© íŒŒì¼ì—ì„œ í™•ì¸
        if self.skip_completed and category_info['name'] in self.completed_categories:
            return True, "ì§„í–‰ìƒí™© íŒŒì¼ì— ê¸°ë¡ë¨"
        
        # 2. ë¶„ë¥˜ê²°ê³¼ í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        result_folder = os.path.join(category_info['parent'], f"{category_info['name']}_ë¶„ë¥˜ê²°ê³¼")
        if os.path.exists(result_folder):
            # ë¶„ë¥˜ê²°ê³¼ í´ë” ë‚´ì— ê·¸ë£¹ í´ë”ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
            group_folders = [f for f in os.listdir(result_folder) 
                           if f.startswith('ê·¸ë£¹_') and os.path.isdir(os.path.join(result_folder, f))]
            
            if group_folders:
                # ê·¸ë£¹ í´ë”ë“¤ì— ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                total_images = 0
                for group_folder in group_folders:
                    group_path = os.path.join(result_folder, group_folder)
                    images_in_group = len([f for f in os.listdir(group_path) 
                                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))])
                    total_images += images_in_group
                
                if total_images > 0:
                    # ì§„í–‰ìƒí™©ì—ë„ ì¶”ê°€
                    self.completed_categories.add(category_info['name'])
                    return True, f"ë¶„ë¥˜ê²°ê³¼ í´ë” ì¡´ì¬ ({len(group_folders)}ê°œ ê·¸ë£¹, {total_images}ê°œ ì´ë¯¸ì§€)"
        
        return False, "ë¯¸ì™„ë£Œ"
        
    def _initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™” ë° ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •"""
        # GPU ë©”ëª¨ë¦¬ ì¦ê°€ í—ˆìš© ì„¤ì •
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            except RuntimeError as e:
                logger.warning(f"GPU ë©”ëª¨ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ)
        self.model = VGG16(weights='imagenet', include_top=False, pooling='avg')
        logger.info("VGG16 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
    def _clear_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜"""
        K.clear_session()
        gc.collect()
        
        if hasattr(tf.config.experimental, 'reset_memory_stats'):
            try:
                tf.config.experimental.reset_memory_stats('GPU:0')
            except:
                pass
    
    def _log_memory_usage(self, step=""):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        process = psutil.Process(os.getpid())
        memory_mb = process.memory_info().rss / 1024 / 1024
        logger.info(f"{step} - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f} MB")
        
    def get_category_folders(self):
        """ì¹´í…Œê³ ë¦¬ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        category_folders = []
        
        for item in os.listdir(self.base_folder):
            item_path = os.path.join(self.base_folder, item)
            if os.path.isdir(item_path):
                subfolders = [f for f in os.listdir(item_path) 
                             if os.path.isdir(os.path.join(item_path, f))]
                
                if subfolders:
                    for subfolder in subfolders:
                        subfolder_path = os.path.join(item_path, subfolder)
                        category_folders.append({
                            'name': f"{item}_{subfolder}",
                            'path': subfolder_path,
                            'parent': item_path
                        })
                else:
                    category_folders.append({
                        'name': item,
                        'path': item_path,
                        'parent': self.base_folder
                    })
        
        return category_folders
    
    def load_images_from_folder(self, folder_path):
        """íŠ¹ì • í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
        image_paths = []
        
        for filename in os.listdir(folder_path):
            if filename.lower().endswith(supported_formats):
                image_paths.append(os.path.join(folder_path, filename))
        
        return image_paths
    
    def extract_features_batch(self, image_paths):
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë°°ì¹˜ íŠ¹ì§• ì¶”ì¶œ"""
        features = []
        valid_paths = []
        
        logger.info(f"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘...")
        self._log_memory_usage("íŠ¹ì§• ì¶”ì¶œ ì‹œì‘")
        
        for i in tqdm(range(0, len(image_paths), self.batch_size)):
            batch_paths = image_paths[i:i+self.batch_size]
            batch_images = []
            batch_valid_paths = []
            
            # ë°°ì¹˜ ì´ë¯¸ì§€ ë¡œë“œ
            for img_path in batch_paths:
                try:
                    img = image.load_img(img_path, target_size=(224, 224))
                    img_array = image.img_to_array(img)
                    img_array = preprocess_input(img_array)
                    batch_images.append(img_array)
                    batch_valid_paths.append(img_path)
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {img_path}: {e}")
                    continue
            
            if batch_images:
                try:
                    # ë°°ì¹˜ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                    batch_array = np.array(batch_images)
                    
                    # íŠ¹ì§• ì¶”ì¶œ
                    with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):
                        batch_features = self.model.predict(batch_array, verbose=0, batch_size=self.batch_size)
                    
                    # ê²°ê³¼ ì €ì¥
                    for j, feature in enumerate(batch_features):
                        features.append(feature.flatten())
                        valid_paths.append(batch_valid_paths[j])
                    
                    # ë°°ì¹˜ ë©”ëª¨ë¦¬ ì •ë¦¬
                    del batch_array, batch_features, batch_images
                    
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
            if i % (self.batch_size * 5) == 0:
                gc.collect()
        
        self._log_memory_usage("íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        return np.array(features), valid_paths
    
    def classify_category(self, category_info):
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        logger.info(f"=== {category_info['name']} ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹œì‘ ===")
        self._log_memory_usage(f"{category_info['name']} ì‹œì‘")
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image_paths = self.load_images_from_folder(category_info['path'])
            
            if len(image_paths) == 0:
                logger.warning(f"{category_info['name']}: ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"{category_info['name']}: {len(image_paths)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
            
            # íŠ¹ì§• ì¶”ì¶œ
            features, valid_paths = self.extract_features_batch(image_paths)
            
            if len(features) == 0:
                logger.warning(f"{category_info['name']}: íŠ¹ì§• ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            
            # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì¡°ì •
            actual_clusters = min(self.n_clusters, len(features))
            
            # ì°¨ì› ì¶•ì†Œ
            logger.info(f"{category_info['name']}: ì°¨ì› ì¶•ì†Œ ì¤‘...")
            n_components = min(50, len(features) - 1)
            pca = PCA(n_components=n_components)
            features_reduced = pca.fit_transform(features)
            
            # í´ëŸ¬ìŠ¤í„°ë§
            logger.info(f"{category_info['name']}: {actual_clusters}ê°œ ê·¸ë£¹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
            kmeans = KMeans(n_clusters=actual_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(features_reduced)
            
            # ê²°ê³¼ ì €ì¥
            self.save_classified_images(category_info, valid_paths, labels, actual_clusters)
            
            # ê²°ê³¼ ìš”ì•½
            self.show_category_summary(category_info['name'], labels, actual_clusters)
            
            # ì§„í–‰ìƒí™© ì €ì¥
            self._save_progress(category_info['name'])
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del features, features_reduced, pca, kmeans, labels
            
        except Exception as e:
            logger.error(f"{category_info['name']} ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # ì¹´í…Œê³ ë¦¬ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬
            self._clear_memory()
            self._log_memory_usage(f"{category_info['name']} ì™„ë£Œ")
    
    def save_classified_images(self, category_info, image_paths, labels, n_clusters):
        """ë¶„ë¥˜ëœ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ í´ë” ë‚´ì— ì €ì¥"""
        logger.info(f"{category_info['name']}: ë¶„ë¥˜ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥ ì¤‘...")
        
        # ì¶œë ¥ í´ë” ìƒì„±
        output_base = os.path.join(category_info['parent'], f"{category_info['name']}_ë¶„ë¥˜ê²°ê³¼")
        
        if os.path.exists(output_base):
            shutil.rmtree(output_base)
        
        os.makedirs(output_base)
        
        # í´ëŸ¬ìŠ¤í„°ë³„ í´ë” ìƒì„±
        for i in range(n_clusters):
            cluster_folder = os.path.join(output_base, f"ê·¸ë£¹_{i+1}")
            os.makedirs(cluster_folder)
        
        # ì´ë¯¸ì§€ ë³µì‚¬
        for img_path, label in tqdm(zip(image_paths, labels), desc="ì´ë¯¸ì§€ ì €ì¥"):
            filename = os.path.basename(img_path)
            dest_folder = os.path.join(output_base, f"ê·¸ë£¹_{label+1}")
            dest_path = os.path.join(dest_folder, filename)
            
            try:
                shutil.copy2(img_path, dest_path)
            except Exception as e:
                logger.warning(f"ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨ {img_path}: {e}")
        
        logger.info(f"{category_info['name']}: ì €ì¥ ì™„ë£Œ -> {output_base}")
    
    def show_category_summary(self, category_name, labels, n_clusters):
        """ì¹´í…Œê³ ë¦¬ë³„ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìš”ì•½"""
        logger.info(f"=== {category_name} ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½ ===")
        for i in range(n_clusters):
            count = np.sum(labels == i)
            percentage = (count / len(labels)) * 100
            logger.info(f"ê·¸ë£¹ {i+1}: {count}ê°œ ì´ë¯¸ì§€ ({percentage:.1f}%)")
    
    def run_all_classifications(self):
        """ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹¤í–‰ (ì™„ë£Œëœ ì¹´í…Œê³ ë¦¬ ìŠ¤í‚µ)"""
        logger.info("ì¹´í…Œê³ ë¦¬ í´ë”ë¥¼ ìŠ¤ìº”í•˜ëŠ” ì¤‘...")
        self._log_memory_usage("ì „ì²´ ì‘ì—… ì‹œì‘")
        
        categories = self.get_category_folders()
        
        if not categories:
            logger.warning("ë¶„ë¥˜í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¹´í…Œê³ ë¦¬ ìƒíƒœ í™•ì¸
        pending_categories = []
        skipped_count = 0
        
        logger.info(f"ì´ {len(categories)}ê°œì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        logger.info("ì¹´í…Œê³ ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘...")
        
        for cat in categories:
            is_completed, reason = self._is_category_completed(cat)
            if is_completed:
                logger.info(f"â­ï¸  SKIP: {cat['name']} - {reason}")
                skipped_count += 1
            else:
                logger.info(f"ğŸ“‹ TODO: {cat['name']} - {reason}")
                pending_categories.append(cat)
        
        logger.info(f"\nğŸ“Š ìƒíƒœ ìš”ì•½:")
        logger.info(f"   - ì™„ë£Œë¨: {skipped_count}ê°œ")
        logger.info(f"   - ì²˜ë¦¬ ëŒ€ê¸°: {len(pending_categories)}ê°œ")
        
        if not pending_categories:
            logger.info("ğŸ‰ ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì´ë¯¸ ë¶„ë¥˜ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            return
        
        # ëŒ€ê¸° ì¤‘ì¸ ì¹´í…Œê³ ë¦¬ë§Œ ì²˜ë¦¬
        logger.info(f"\nğŸš€ {len(pending_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        for idx, category in enumerate(pending_categories):
            try:
                logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {idx+1}/{len(pending_categories)} (ì „ì²´: {skipped_count + idx + 1}/{len(categories)})")
                self.classify_category(category)
                
                # ì¹´í…Œê³ ë¦¬ ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
                if idx % 3 == 0:
                    self._clear_memory()
                    
            except Exception as e:
                logger.error(f"{category['name']} ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        logger.info("ğŸ‰ ì „ì²´ ë¶„ë¥˜ ì‘ì—… ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… ê²°ê³¼: {len(self.completed_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ì™„ë£Œ")
        self._log_memory_usage("ì „ì²´ ì‘ì—… ì™„ë£Œ")
    
    def reset_progress(self):
        """ì§„í–‰ìƒí™© ì´ˆê¸°í™” (ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•˜ê³  ì‹¶ì„ ë•Œ)"""
        if os.path.exists(self.progress_file):
            os.remove(self.progress_file)
            logger.info("ì§„í–‰ìƒí™©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.completed_categories = set()
    
    def show_progress_status(self):
        """í˜„ì¬ ì§„í–‰ìƒí™© í‘œì‹œ"""
        categories = self.get_category_folders()
        completed_count = 0
        
        logger.info("=== í˜„ì¬ ì§„í–‰ìƒí™© ===")
        for cat in categories:
            is_completed, reason = self._is_category_completed(cat)
            status = "âœ… ì™„ë£Œ" if is_completed else "â³ ëŒ€ê¸°"
            logger.info(f"{status}: {cat['name']} - {reason}")
            if is_completed:
                completed_count += 1
        
        logger.info(f"\nğŸ“Š ì „ì²´ ì§„í–‰ë¥ : {completed_count}/{len(categories)} ({completed_count/len(categories)*100:.1f}%)")
    
    def __del__(self):
        """ì†Œë©¸ìì—ì„œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            if hasattr(self, 'model') and self.model is not None:
                del self.model
            self._clear_memory()
        except:
            pass


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    BASE_FOLDER = "C:/Users/AI-LHJ/Desktop/task/images/ë¡œë§¨í‹±/ë¡œë§¨í‹±_001_reg_ë·´ë¥˜ê²°ê³¼/ê·¸ë£¹_16"
    N_CLUSTERS = 20
    BATCH_SIZE = 4
    
    try:
        # ë¶„ë¥˜ê¸° ìƒì„±
        classifier = MultiCategoryImageClassifier(
            BASE_FOLDER, 
            N_CLUSTERS, 
            batch_size=BATCH_SIZE,
            skip_completed=True  # ì™„ë£Œëœ ì¹´í…Œê³ ë¦¬ ìŠ¤í‚µ í™œì„±í™”
        )
        
        # í˜„ì¬ ì§„í–‰ìƒí™© í™•ì¸ (ì„ íƒì‚¬í•­)
        classifier.show_progress_status()
        
        # ì§„í–‰ìƒí™© ì´ˆê¸°í™” (í•„ìš”ì‹œ)
        # classifier.reset_progress()
        
        # ë¶„ë¥˜ ì‹¤í–‰ (ì™„ë£Œëœ ì¹´í…Œê³ ë¦¬ëŠ” ìë™ìœ¼ë¡œ ìŠ¤í‚µë¨)
        classifier.run_all_classifications()
        
        logger.info("âœ… ëª¨ë“  ì´ë¯¸ì§€ ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ“ ê° ì¹´í…Œê³ ë¦¬ í´ë” ë‚´ì—ì„œ '_ë¶„ë¥˜ê²°ê³¼' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
    finally:
        # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬
        K.clear_session()
        gc.collect()
